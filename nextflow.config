manifest {
  author = "Jeff Vierstra & Sergey Abramov"
  mainScript = "main.nf"
  defaultBranch = "main"
  name = "dhs-index-pipeline"
  description = "Build a DHS matrices from BAM files and hotspots"
  version = "0.1"
  nextflowVersion = "22.04.0"
}

// Run with a stricter shell, so errors are caught earlier
process.shell = ['/bin/bash', '-ueo','pipefail' ]

params {
	includeConfig './params.config'
}

profiles {
	Altius {
		// Run on SLURM and load the appropriate modules	
		process {
			executor = "slurm"
			queue = "queue0,queue2,encode4,pool,bigmem"
			memory = { 8.GB * task.attempt }
			cache = "lenient"
			errorStrategy = { (task.exitStatus == 137 || task.exitStatus == 143 || task.exitStatus == 141) ? 'retry' : 'terminate' }
			maxRetries = 3
			withLabel: bigmem {
				cpus = 50
				memory = 1500.GB
				queue = 'bigmem'
			}
			withLabel: gpu {
				clusterOptions = "--gpus=4"
				queue = "hpcz-1,hpcz-1-short"
				maxRetries = 1
				memory = 200.GB
				beforeScript = "module load cuda/11.2.0; module load cudnn/8.1; module load tensorflow-gpu/2.3; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/sabramov/miniconda3/envs/jupyter-gpu/lib/python3.10/site-packages/tensorrt/"
			}
 		}
		
		executor {
			$slurm {
				queueSize = 300
			}
		}
			
		// Logging
		// trace.enabled = true
		// trace.file = "pipeline_trace.txt"
		// timeline.enabled = true
		// timeline.file = "pipeline_timeline.html"
		// report.enabled = true
		// report.file = "pipeline_report.html"
	}
}
