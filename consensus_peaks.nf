include { generate_matrix; extract_meta_from_anndata } from "./generate_matrices"



process extract_pval {
    tag "${id}"
    //publishDir "${params.outdir}/${id}"
    conda "/home/sabramov/miniconda3/envs/jupyterlab"
    label 'high_mem'

    input:
        tuple val(id), path(pvals_parquet), path(bed_file)

    output:
        tuple val(id), path(name)

    script:
    name = "${id}.max_pvals.npy"
    """
    hotspot3-pvals \
        ${pvals_parquet} \
        ${bed_file} \
        ${name} \
        --chrom_sizes ${params.nuclear_chrom_sizes} \
        --format npy
    """
}


workflow extractMaxPvalue {
    println "Taking samples order from anndata input (generated by build_index.nf) in - params.index_anndata = ${params.index_anndata}"


    index_meta = Channel.of(params.index_anndata)
        | extract_meta_from_anndata // path(masterlist), path(samples_order), path(saf_masterlist)
        | map(it -> tuple(it[0], it[1]))

    params.template_run = "/net/seq/data2/projects/sabramov/SuperIndex/hotspot3/peak_calls.v23/"

    data = Channel.fromPath(params.samples_file)
        | splitCsv(header:true, sep:'\t')
        | map(row -> tuple(
                row.ag_id,
                file("${params.template_run}/${row.ag_id}/${row.ag_id}.pvals.parquet")
            )
        )
        | combine(index_meta)
        | map(it -> tuple(it[0], it[1], it[2]))
        | extract_pval
        | map(it -> tuple("neglog10_pval", it[1]))
        | combine(index_meta.map(it -> it[1])) // prefix, pvals, samples_order
        | groupTuple(by: 0) // prefix, pvals, samples_order
        | generate_matrix
}


process core_set {

    conda params.conda
    publishDir "${params.outdir}/core_sets/${params.grouping_column}"

    input:
        tuple val(grouping_key), path(pvals), path(anndata)
    
    output:
        tuple val(grouping_key), path(name)
    
    script:
    name = "${grouping_key}.core_set.bonf${params.core_set_fdr}.bed"
    """
    python3 $moduleDir/bin/core_sets/core_set.py \
        ${params.samples_file} \
        ${params.grouping_column} \
        ${grouping_key} \
        ${anndata} \
        ${pvals} \
        ${params.core_set_fdr} \
        ${name}
    """
}


workflow generateCoreSets {
    params.core_set_fdr = 0.001
    println "Using ${params.grouping_column} as grouping column"
    params.pvals_matrix = "${params.outdir}/raw_matrices/matrix.neglog10_pval.npy"
    data = Channel.fromPath(params.samples_file)
        | splitCsv(header:true, sep:'\t')
        | map(row -> tuple(
                row[params.grouping_column]
            )
        )
        | unique()
        | map(it -> tuple(it[0], file(params.pvals_matrix), file(params.index_anndata)))
        | core_set
        | collectFile (
            skip: 1,
            keepHeader: true,
            storeDir: "${params.outdir}/core_sets/${params.grouping_column}",
        ) { it -> [ 
            "core_sets_meta.tsv", 
            "group_key\tcore_set_bed\n${it[0]}\t${params.outdir}/core_sets/${params.grouping_column}/${it[1].name}\n" 
            ] 
        }
}